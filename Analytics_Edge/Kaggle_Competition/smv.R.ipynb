{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(rpart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TrainImp = read.csv(\"pollTrain_imputed.csv\")\n",
    "TestImp = read.csv(\"pollTest_imputed.csv\")\n",
    "TrainImp$USER_ID = NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5568 obs. of  107 variables:\n",
      " $ YOB            : int  1938 1970 1997 1983 1984 1997 1983 1996 1994 1981 ...\n",
      " $ Gender         : Factor w/ 2 levels \"Female\",\"Male\": 2 1 2 2 1 1 2 2 2 1 ...\n",
      " $ Income         : Factor w/ 6 levels \"$100,001 - $150,000\",..: 4 5 4 1 3 5 2 4 6 3 ...\n",
      " $ HouseholdStatus: Factor w/ 6 levels \"Domestic Partners (no kids)\",..: 4 2 5 4 4 5 3 5 5 4 ...\n",
      " $ EducationLevel : Factor w/ 7 levels \"Associate's Degree\",..: 2 2 6 2 6 3 4 3 3 2 ...\n",
      " $ Party          : Factor w/ 2 levels \"Democrat\",\"Republican\": 1 1 2 1 2 1 1 2 2 2 ...\n",
      " $ Q124742        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 2 1 1 ...\n",
      " $ Q124122        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 2 1 1 2 1 1 ...\n",
      " $ Q123464        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 2 1 ...\n",
      " $ Q123621        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 2 1 1 1 ...\n",
      " $ Q122769        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 2 1 2 2 ...\n",
      " $ Q122770        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 1 2 2 1 2 2 1 ...\n",
      " $ Q122771        : Factor w/ 2 levels \"Private\",\"Public\": 2 2 1 2 2 2 2 1 2 2 ...\n",
      " $ Q122120        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 2 2 1 ...\n",
      " $ Q121699        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 2 1 2 1 1 2 ...\n",
      " $ Q121700        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ Q120978        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 2 2 2 1 2 2 ...\n",
      " $ Q121011        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 2 1 1 2 ...\n",
      " $ Q120379        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 2 2 2 1 ...\n",
      " $ Q120650        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ Q120472        : Factor w/ 2 levels \"Art\",\"Science\": 2 2 2 2 1 2 2 2 2 1 ...\n",
      " $ Q120194        : Factor w/ 2 levels \"Study first\",..: 2 1 1 2 2 2 1 2 1 2 ...\n",
      " $ Q120012        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 2 2 2 1 1 2 ...\n",
      " $ Q120014        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 2 1 2 1 1 ...\n",
      " $ Q119334        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 1 1 1 1 1 1 ...\n",
      " $ Q119851        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 2 2 1 1 2 ...\n",
      " $ Q119650        : Factor w/ 2 levels \"Giving\",\"Receiving\": 2 2 2 1 1 2 1 2 2 1 ...\n",
      " $ Q118892        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 1 1 1 2 2 1 ...\n",
      " $ Q118117        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 1 2 2 ...\n",
      " $ Q118232        : Factor w/ 2 levels \"Idealist\",\"Pragmatist\": 1 2 2 1 1 2 2 1 1 1 ...\n",
      " $ Q118233        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 2 ...\n",
      " $ Q118237        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 2 1 2 2 2 2 ...\n",
      " $ Q117186        : Factor w/ 2 levels \"Cool headed\",..: 2 1 1 1 2 1 1 1 1 1 ...\n",
      " $ Q117193        : Factor w/ 2 levels \"Odd hours\",\"Standard hours\": 1 2 1 2 2 2 1 2 2 2 ...\n",
      " $ Q116797        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 1 1 2 ...\n",
      " $ Q116881        : Factor w/ 2 levels \"Happy\",\"Right\": 1 1 2 1 1 2 1 2 1 1 ...\n",
      " $ Q116953        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 1 1 2 1 ...\n",
      " $ Q116601        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 2 2 2 1 1 2 ...\n",
      " $ Q116441        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 1 1 1 1 2 ...\n",
      " $ Q116448        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 2 2 2 1 1 2 ...\n",
      " $ Q116197        : Factor w/ 2 levels \"A.M.\",\"P.M.\": 2 1 1 1 2 2 2 2 2 2 ...\n",
      " $ Q115602        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 1 2 2 2 2 2 ...\n",
      " $ Q115777        : Factor w/ 2 levels \"End\",\"Start\": 2 1 2 2 1 2 1 2 2 2 ...\n",
      " $ Q115610        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 2 2 2 2 ...\n",
      " $ Q115611        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 2 1 2 ...\n",
      " $ Q115899        : Factor w/ 2 levels \"Circumstances\",..: 1 2 1 1 2 1 2 1 2 2 ...\n",
      " $ Q115390        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 1 2 2 1 2 2 ...\n",
      " $ Q114961        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 1 2 2 2 1 2 1 ...\n",
      " $ Q114748        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 2 1 1 2 2 1 ...\n",
      " $ Q115195        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 1 2 1 ...\n",
      " $ Q114517        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 2 1 1 1 1 1 ...\n",
      " $ Q114386        : Factor w/ 2 levels \"Mysterious\",\"TMI\": 1 1 1 2 2 1 2 1 1 2 ...\n",
      " $ Q113992        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 2 2 1 1 1 1 ...\n",
      " $ Q114152        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 1 1 2 ...\n",
      " $ Q113583        : Factor w/ 2 levels \"Talk\",\"Tunes\": 1 1 2 1 2 2 2 2 2 2 ...\n",
      " $ Q113584        : Factor w/ 2 levels \"People\",\"Technology\": 2 2 2 1 1 2 2 1 2 2 ...\n",
      " $ Q113181        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 2 2 1 2 ...\n",
      " $ Q112478        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 2 1 1 2 1 ...\n",
      " $ Q112512        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ Q112270        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 1 2 ...\n",
      " $ Q111848        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 2 2 2 2 1 ...\n",
      " $ Q111580        : Factor w/ 2 levels \"Demanding\",\"Supportive\": 1 1 2 2 1 2 2 1 1 1 ...\n",
      " $ Q111220        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 2 ...\n",
      " $ Q110740        : Factor w/ 2 levels \"Mac\",\"PC\": 2 1 2 1 2 2 2 2 2 2 ...\n",
      " $ Q109367        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 1 2 1 1 2 ...\n",
      " $ Q108950        : Factor w/ 2 levels \"Cautious\",\"Risk-friendly\": 1 1 1 2 1 1 1 1 1 1 ...\n",
      " $ Q109244        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 1 ...\n",
      " $ Q108855        : Factor w/ 2 levels \"Umm...\",\"Yes!\": 2 1 1 1 2 2 1 2 1 2 ...\n",
      " $ Q108617        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ Q108856        : Factor w/ 2 levels \"Socialize\",\"Space\": 2 2 2 1 1 2 2 1 2 1 ...\n",
      " $ Q108754        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 2 1 1 1 1 ...\n",
      " $ Q108342        : Factor w/ 2 levels \"In-person\",\"Online\": 1 1 1 2 2 1 2 1 2 2 ...\n",
      " $ Q108343        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 2 ...\n",
      " $ Q107869        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 1 1 1 1 1 2 ...\n",
      " $ Q107491        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 2 2 2 2 2 2 ...\n",
      " $ Q106993        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 1 2 2 2 ...\n",
      " $ Q106997        : Factor w/ 2 levels \"Grrr people\",..: 2 2 1 1 2 1 1 1 1 2 ...\n",
      " $ Q106272        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 1 2 2 2 2 1 1 ...\n",
      " $ Q106388        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 1 1 1 1 1 ...\n",
      " $ Q106389        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 2 2 2 2 2 1 ...\n",
      " $ Q106042        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 2 2 1 1 1 2 ...\n",
      " $ Q105840        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 2 1 2 1 1 2 ...\n",
      " $ Q105655        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 2 1 1 2 2 2 ...\n",
      " $ Q104996        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 1 2 1 1 1 2 ...\n",
      " $ Q103293        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 2 2 2 2 2 ...\n",
      " $ Q102906        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 2 1 1 2 ...\n",
      " $ Q102674        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " $ Q102687        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 1 2 2 1 ...\n",
      " $ Q102289        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 1 1 1 ...\n",
      " $ Q102089        : Factor w/ 2 levels \"Own\",\"Rent\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ Q101162        : Factor w/ 2 levels \"Optimist\",\"Pessimist\": 1 1 2 1 1 2 2 2 1 1 ...\n",
      " $ Q101163        : Factor w/ 2 levels \"Dad\",\"Mom\": 2 2 2 2 2 2 2 2 1 2 ...\n",
      " $ Q101596        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 2 1 1 ...\n",
      " $ Q100689        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 2 1 2 2 1 2 ...\n",
      " $ Q100680        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 2 2 2 1 2 2 ...\n",
      " $ Q100562        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 2 2 2 2 1 2 ...\n",
      " $ Q99982         : Factor w/ 2 levels \"Check!\",\"Nope\": 2 2 2 1 2 2 2 2 2 1 ...\n",
      " $ Q100010        : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 2 2 2 2 2 2 ...\n",
      " $ Q99716         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      "  [list output truncated]\n"
     ]
    }
   ],
   "source": [
    "str(TrainImp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainImp$Party = as.factor(ifelse(TrainImp$Party==\"Democrat\",1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "2617 2951 "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table(TrainImp$Party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(caTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = sample.split(TrainImp$Party, SplitRatio = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = subset(TrainImp, split == TRUE)\n",
    "Test = subset(TrainImp, split == FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "1963 2213 "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "4176"
      ],
      "text/latex": [
       "4176"
      ],
      "text/markdown": [
       "4176"
      ],
      "text/plain": [
       "[1] 4176"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table(Train$Party)\n",
    "nrow(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmModel = svm(Party~., data = Train, cost=1000, gamma = 10, type = \"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = Party ~ ., data = Train, cost = 1000, gamma = 10, type = \"C\")\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  C-classification \n",
       " SVM-Kernel:  radial \n",
       "       cost:  1000 \n",
       "      gamma:  10 \n",
       "\n",
       "Number of Support Vectors:  4176\n",
       "\n",
       " ( 2213 1963 )\n",
       "\n",
       "\n",
       "Number of Classes:  2 \n",
       "\n",
       "Levels: \n",
       " 0 1\n",
       "\n",
       "\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(svmModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predTest = predict(svmModel, newdata = Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predTest\n",
       "   0    1 \n",
       "1963 2213 "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table(predTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in table(Test$Party, predTest): all arguments must have the same length\n",
     "output_type": "error",
     "traceback": [
      "Error in table(Test$Party, predTest): all arguments must have the same length\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   predTest\n",
       "      0   1\n",
       "  0   0 654\n",
       "  1   0 738"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = table(Test$Party,predTest)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>0</dt>\n",
       "\t\t<dd>1963</dd>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>2213</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 1963\n",
       "\\item[1] 2213\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   19631\n",
       ":   2213\n",
       "\n"
      ],
      "text/plain": [
       "   0    1 \n",
       "1963 2213 "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(predTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for svm {e1071}\"><tr><td>svm {e1071}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Support Vector Machines</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>svm</code> is used to train a support vector machine. It can be used to carry\n",
       "out general regression and classification (of nu and epsilon-type), as\n",
       "well as density-estimation. A formula interface is provided.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "## S3 method for class 'formula'\n",
       "svm(formula, data = NULL, ..., subset, na.action =\n",
       "na.omit, scale = TRUE)\n",
       "## Default S3 method:\n",
       "svm(x, y = NULL, scale = TRUE, type = NULL, kernel =\n",
       "\"radial\", degree = 3, gamma = if (is.vector(x)) 1 else 1 / ncol(x),\n",
       "coef0 = 0, cost = 1, nu = 0.5,\n",
       "class.weights = NULL, cachesize = 40, tolerance = 0.001, epsilon = 0.1,\n",
       "shrinking = TRUE, cross = 0, probability = FALSE, fitted = TRUE,\n",
       "..., subset, na.action = na.omit)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula</code></td>\n",
       "<td>\n",
       "<p>a symbolic description of the model to be fit.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>data</code></td>\n",
       "<td>\n",
       "<p>an optional data frame containing the variables in the model.\n",
       "By default the variables are taken from the environment which\n",
       "&lsquo;svm&rsquo; is called from.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>a data matrix, a vector, or a sparse matrix (object of class\n",
       "<code>Matrix</code> provided by the <span class=\"pkg\">Matrix</span> package,\n",
       "or of class <code>matrix.csr</code>\n",
       "provided by the <span class=\"pkg\">SparseM</span> package, or of class\n",
       "<code>simple_triplet_matrix</code> provided by the <span class=\"pkg\">slam</span>\n",
       "package).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "<p>a response vector with one label for each row/component of\n",
       "<code>x</code>. Can be either a factor (for classification tasks)\n",
       "or a numeric vector (for regression).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>scale</code></td>\n",
       "<td>\n",
       "<p>A logical vector indicating the variables to be\n",
       "scaled. If <code>scale</code> is of length 1, the value is recycled as\n",
       "many times as needed.\n",
       "Per default, data are scaled internally (both <code>x</code> and <code>y</code>\n",
       "variables) to zero mean and unit variance. The center and scale\n",
       "values are returned and used for later predictions.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type</code></td>\n",
       "<td>\n",
       "<p><code>svm</code> can be used as a classification\n",
       "machine, as a regression machine, or for novelty detection.\n",
       "Depending of whether <code>y</code> is\n",
       "a factor or not, the default setting for <code>type</code> is <code>C-classification</code> or <code>eps-regression</code>, respectively, but may be overwritten by setting an explicit value.<br />\n",
       "Valid options are:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>C-classification</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>nu-classification</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>one-classification</code> (for novelty detection)\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>eps-regression</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>nu-regression</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>kernel</code></td>\n",
       "<td>\n",
       "<p>the kernel used in training and predicting. You\n",
       "might consider changing some of the following parameters, depending\n",
       "on the kernel type.<br />\n",
       "</p>\n",
       "\n",
       "<dl>\n",
       "<dt>linear:</dt><dd><p><i>u'*v</i></p>\n",
       "</dd>\n",
       "<dt>polynomial:</dt><dd><p><i>(gamma*u'*v + coef0)^degree</i></p>\n",
       "</dd>\n",
       "<dt>radial basis:</dt><dd><p><i>exp(-gamma*|u-v|^2)</i></p>\n",
       "</dd>\n",
       "<dt>sigmoid:</dt><dd><p><i>tanh(gamma*u'*v + coef0)</i></p>\n",
       "</dd>\n",
       "</dl>\n",
       "\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>degree</code></td>\n",
       "<td>\n",
       "<p>parameter needed for kernel of type <code>polynomial</code> (default: 3)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>gamma</code></td>\n",
       "<td>\n",
       "<p>parameter needed for all kernels except <code>linear</code>\n",
       "(default: 1/(data dimension))</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>coef0</code></td>\n",
       "<td>\n",
       "<p>parameter needed for kernels of type <code>polynomial</code>\n",
       "and <code>sigmoid</code> (default: 0)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>cost</code></td>\n",
       "<td>\n",
       "<p>cost of constraints violation (default: 1)&mdash;it is the\n",
       "&lsquo;C&rsquo;-constant of the regularization term in the Lagrange formulation.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nu</code></td>\n",
       "<td>\n",
       "<p>parameter needed for <code>nu-classification</code>,\n",
       "<code>nu-regression</code>, and <code>one-classification</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>class.weights</code></td>\n",
       "<td>\n",
       "<p>a named vector of weights for the different\n",
       "classes, used for asymmetric class sizes. Not all factor levels have\n",
       "to be supplied (default weight: 1). All components have to be named.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>cachesize</code></td>\n",
       "<td>\n",
       "<p>cache memory in MB (default 40)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>tolerance</code></td>\n",
       "<td>\n",
       "<p>tolerance of termination criterion (default: 0.001)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>epsilon</code></td>\n",
       "<td>\n",
       "<p>epsilon in the insensitive-loss function (default: 0.1)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>shrinking</code></td>\n",
       "<td>\n",
       "<p>option whether to use the shrinking-heuristics\n",
       "(default: <code>TRUE</code>)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>cross</code></td>\n",
       "<td>\n",
       "<p>if a integer value k&gt;0 is specified, a k-fold cross\n",
       "validation on the training data is performed to assess the quality\n",
       "of the model: the accuracy rate for classification and the Mean\n",
       "Squared Error for regression</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fitted</code></td>\n",
       "<td>\n",
       "<p>logical indicating whether the fitted values should be computed\n",
       "and included in the model or not (default: <code>TRUE</code>)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>probability</code></td>\n",
       "<td>\n",
       "<p>logical indicating whether the model should\n",
       "allow for probability predictions.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>additional parameters for the low level fitting function\n",
       "<code>svm.default</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>subset</code></td>\n",
       "<td>\n",
       "<p>An index vector specifying the cases to be used in the\n",
       "training sample.  (NOTE: If given, this argument must be\n",
       "named.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action</code></td>\n",
       "<td>\n",
       "<p>A function to specify the action to be taken if <code>NA</code>s are\n",
       "found. The default action is <code>na.omit</code>, which leads to rejection of cases\n",
       "with missing values on any required variable. An alternative\n",
       "is <code>na.fail</code>, which causes an error if <code>NA</code> cases\n",
       "are found. (NOTE: If given, this argument must be named.)</p>\n",
       "</td></tr>\t\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>For multiclass-classification with k levels, k&gt;2, <code>libsvm</code> uses the\n",
       "&lsquo;one-against-one&rsquo;-approach, in which k(k-1)/2 binary classifiers are\n",
       "trained; the appropriate class is found by a voting scheme.\n",
       "</p>\n",
       "<p><code>libsvm</code> internally uses a sparse data representation, which is \n",
       "also high-level supported by the package <span class=\"pkg\">SparseM</span>.\n",
       "</p>\n",
       "<p>If the predictor variables include factors, the formula interface must be used to get a\n",
       "correct model matrix.\n",
       "</p>\n",
       "<p><code>plot.svm</code> allows a simple graphical\n",
       "visualization of classification models.\n",
       "</p>\n",
       "<p>The probability model for classification fits a logistic distribution\n",
       "using maximum likelihood to the decision values of all binary\n",
       "classifiers, and computes the a-posteriori class probabilities for the\n",
       "multi-class problem using quadratic optimization. The probabilistic\n",
       "regression model assumes (zero-mean) laplace-distributed errors for the\n",
       "predictions, and estimates the scale parameter using maximum likelihood.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>An object of class <code>\"svm\"</code> containing the fitted model, including:\n",
       "</p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>SV</code></td>\n",
       "<td>\n",
       "<p>The resulting support vectors (possibly scaled).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>index</code></td>\n",
       "<td>\n",
       "<p>The index of the resulting support vectors in the data\n",
       "matrix. Note that this index refers to the preprocessed data (after\n",
       "the possible effect of <code>na.omit</code> and <code>subset</code>)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>coefs</code></td>\n",
       "<td>\n",
       "<p>The corresponding coefficients times the training labels.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>rho</code></td>\n",
       "<td>\n",
       "<p>The negative intercept.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sigma</code></td>\n",
       "<td>\n",
       "<p>In case of a probabilistic regression model, the scale\n",
       "parameter of the hypothesized (zero-mean) laplace distribution estimated by\n",
       "maximum likelihood.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>probA, probB</code></td>\n",
       "<td>\n",
       "<p>numeric vectors of length k(k-1)/2, k number of\n",
       "classes, containing the parameters of the logistic distributions fitted to\n",
       "the decision values of the binary classifiers (1 / (1 + exp(a x + b))).</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>Data are scaled internally, usually yielding better results.\n",
       "</p>\n",
       "<p>Parameters of SVM-models usually <em>must</em> be tuned to yield sensible results!\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin)<br />\n",
       "<a href=\"mailto:David.Meyer@R-project.org\">David.Meyer@R-project.org</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "\n",
       "<ul>\n",
       "<li>\n",
       "<p>Chang, Chih-Chung and Lin, Chih-Jen:<br />\n",
       "<em>LIBSVM: a library for Support Vector Machines</em><br />\n",
       "<a href=\"http://www.csie.ntu.edu.tw/~cjlin/libsvm\">http://www.csie.ntu.edu.tw/~cjlin/libsvm</a>\n",
       "</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>Exact formulations of models, algorithms, etc. can be found in the\n",
       "document:<br />\n",
       "Chang, Chih-Chung and Lin, Chih-Jen:<br />\n",
       "<em>LIBSVM: a library for Support Vector Machines</em><br />\n",
       "<a href=\"http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz\">http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz</a>\n",
       "</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>More implementation details and speed benchmarks can be found on:\n",
       "Rong-En Fan and Pai-Hsune Chen and Chih-Jen Lin:<br />\n",
       "<em>Working Set Selection Using the Second Order Information for Training SVM</em><br />\n",
       "<a href=\"http://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf\">http://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf</a>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>predict.svm</code>\n",
       "<code>plot.svm</code>\n",
       "<code>tune.svm</code>\n",
       "<code>matrix.csr</code> (in package <span class=\"pkg\">SparseM</span>)\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "data(iris)\n",
       "attach(iris)\n",
       "\n",
       "## classification mode\n",
       "# default with factor response:\n",
       "model &lt;- svm(Species ~ ., data = iris)\n",
       "\n",
       "# alternatively the traditional interface:\n",
       "x &lt;- subset(iris, select = -Species)\n",
       "y &lt;- Species\n",
       "model &lt;- svm(x, y) \n",
       "\n",
       "print(model)\n",
       "summary(model)\n",
       "\n",
       "# test with train data\n",
       "pred &lt;- predict(model, x)\n",
       "# (same as:)\n",
       "pred &lt;- fitted(model)\n",
       "\n",
       "# Check accuracy:\n",
       "table(pred, y)\n",
       "\n",
       "# compute decision values and probabilities:\n",
       "pred &lt;- predict(model, x, decision.values = TRUE)\n",
       "attr(pred, \"decision.values\")[1:4,]\n",
       "\n",
       "# visualize (classes by color, SV by crosses):\n",
       "plot(cmdscale(dist(iris[,-5])),\n",
       "     col = as.integer(iris[,5]),\n",
       "     pch = c(\"o\",\"+\")[1:150 %in% model$index + 1])\n",
       "\n",
       "## try regression mode on two dimensions\n",
       "\n",
       "# create data\n",
       "x &lt;- seq(0.1, 5, by = 0.05)\n",
       "y &lt;- log(x) + rnorm(x, sd = 0.2)\n",
       "\n",
       "# estimate model and predict input values\n",
       "m   &lt;- svm(x, y)\n",
       "new &lt;- predict(m, x)\n",
       "\n",
       "# visualize\n",
       "plot(x, y)\n",
       "points(x, log(x), col = 2)\n",
       "points(x, new, col = 4)\n",
       "\n",
       "## density-estimation\n",
       "\n",
       "# create 2-dim. normal with rho=0:\n",
       "X &lt;- data.frame(a = rnorm(1000), b = rnorm(1000))\n",
       "attach(X)\n",
       "\n",
       "# traditional way:\n",
       "m &lt;- svm(X, gamma = 0.1)\n",
       "\n",
       "# formula interface:\n",
       "m &lt;- svm(~., data = X, gamma = 0.1)\n",
       "# or:\n",
       "m &lt;- svm(~ a + b, gamma = 0.1)\n",
       "\n",
       "# test:\n",
       "newdata &lt;- data.frame(a = c(0, 4), b = c(0, 4))\n",
       "predict (m, newdata)\n",
       "\n",
       "# visualize:\n",
       "plot(X, col = 1:1000 %in% m$index + 1, xlim = c(-5,5), ylim=c(-5,5))\n",
       "points(newdata, pch = \"+\", col = 2, cex = 5)\n",
       "\n",
       "# weights: (example not particularly sensible)\n",
       "i2 &lt;- iris\n",
       "levels(i2$Species)[3] &lt;- \"versicolor\"\n",
       "summary(i2$Species)\n",
       "wts &lt;- 100 / table(i2$Species)\n",
       "wts\n",
       "m &lt;- svm(Species ~ ., data = i2, class.weights = wts)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>e1071</em> version 1.6-7 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{svm}{Support Vector Machines}{svm}\n",
       "\\aliasA{print.summary.svm}{svm}{print.summary.svm}\n",
       "\\aliasA{print.svm}{svm}{print.svm}\n",
       "\\aliasA{summary.svm}{svm}{summary.svm}\n",
       "\\methaliasA{svm.default}{svm}{svm.default}\n",
       "\\methaliasA{svm.formula}{svm}{svm.formula}\n",
       "\\keyword{neural}{svm}\n",
       "\\keyword{nonlinear}{svm}\n",
       "\\keyword{classif}{svm}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{svm} is used to train a support vector machine. It can be used to carry\n",
       "out general regression and classification (of nu and epsilon-type), as\n",
       "well as density-estimation. A formula interface is provided.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "## S3 method for class 'formula'\n",
       "svm(formula, data = NULL, ..., subset, na.action =\n",
       "na.omit, scale = TRUE)\n",
       "## Default S3 method:\n",
       "svm(x, y = NULL, scale = TRUE, type = NULL, kernel =\n",
       "\"radial\", degree = 3, gamma = if (is.vector(x)) 1 else 1 / ncol(x),\n",
       "coef0 = 0, cost = 1, nu = 0.5,\n",
       "class.weights = NULL, cachesize = 40, tolerance = 0.001, epsilon = 0.1,\n",
       "shrinking = TRUE, cross = 0, probability = FALSE, fitted = TRUE,\n",
       "..., subset, na.action = na.omit)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula}] a symbolic description of the model to be fit.\n",
       "\\item[\\code{data}] an optional data frame containing the variables in the model.\n",
       "By default the variables are taken from the environment which\n",
       "`svm' is called from.\n",
       "\\item[\\code{x}] a data matrix, a vector, or a sparse matrix (object of class\n",
       "\\code{\\LinkA{Matrix}{Matrix}} provided by the \\pkg{Matrix} package,\n",
       "or of class \\code{\\LinkA{matrix.csr}{matrix.csr}}\n",
       "provided by the \\pkg{SparseM} package, or of class\n",
       "\\code{\\LinkA{simple\\_triplet\\_matrix}{simple.Rul.triplet.Rul.matrix}} provided by the \\pkg{slam}\n",
       "package).\n",
       "\\item[\\code{y}] a response vector with one label for each row/component of\n",
       "\\code{x}. Can be either a factor (for classification tasks)\n",
       "or a numeric vector (for regression).\n",
       "\\item[\\code{scale}] A logical vector indicating the variables to be\n",
       "scaled. If \\code{scale} is of length 1, the value is recycled as\n",
       "many times as needed.\n",
       "Per default, data are scaled internally (both \\code{x} and \\code{y}\n",
       "variables) to zero mean and unit variance. The center and scale\n",
       "values are returned and used for later predictions.\n",
       "\\item[\\code{type}] \\code{svm} can be used as a classification\n",
       "machine, as a regression machine, or for novelty detection.\n",
       "Depending of whether \\code{y} is\n",
       "a factor or not, the default setting for \\code{type} is \\code{C-classification} or \\code{eps-regression}, respectively, but may be overwritten by setting an explicit value.\\\\{}\n",
       "Valid options are:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{C-classification}\n",
       "\\item \\code{nu-classification}\n",
       "\\item \\code{one-classification} (for novelty detection)\n",
       "\\item \\code{eps-regression}\n",
       "\\item \\code{nu-regression}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "\\item[\\code{kernel}] the kernel used in training and predicting. You\n",
       "might consider changing some of the following parameters, depending\n",
       "on the kernel type.\\\\{}\n",
       "\\begin{description}\n",
       "\n",
       "\\item[linear:] \\eqn{u'v}{}\n",
       "\\item[polynomial:] \\eqn{(\\gamma u'v + coef0)^{degree}}{}\n",
       "\\item[radial basis:] \\eqn{e^(-\\gamma |u-v|^2)}{}\n",
       "\\item[sigmoid:] \\eqn{tanh(\\gamma u'v + coef0)}{}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\n",
       "\\item[\\code{degree}] parameter needed for kernel of type \\code{polynomial} (default: 3)\n",
       "\\item[\\code{gamma}] parameter needed for all kernels except \\code{linear}\n",
       "(default: 1/(data dimension))\n",
       "\\item[\\code{coef0}] parameter needed for kernels of type \\code{polynomial}\n",
       "and \\code{sigmoid} (default: 0)\n",
       "\\item[\\code{cost}] cost of constraints violation (default: 1)---it is the\n",
       "`C'-constant of the regularization term in the Lagrange formulation.\n",
       "\\item[\\code{nu}] parameter needed for \\code{nu-classification},\n",
       "\\code{nu-regression}, and \\code{one-classification}\n",
       "\\item[\\code{class.weights}] a named vector of weights for the different\n",
       "classes, used for asymmetric class sizes. Not all factor levels have\n",
       "to be supplied (default weight: 1). All components have to be named.\n",
       "\\item[\\code{cachesize}] cache memory in MB (default 40)\n",
       "\\item[\\code{tolerance}] tolerance of termination criterion (default: 0.001)\n",
       "\\item[\\code{epsilon}] epsilon in the insensitive-loss function (default: 0.1)\n",
       "\\item[\\code{shrinking}] option whether to use the shrinking-heuristics\n",
       "(default: \\code{TRUE})\n",
       "\\item[\\code{cross}] if a integer value k>0 is specified, a k-fold cross\n",
       "validation on the training data is performed to assess the quality\n",
       "of the model: the accuracy rate for classification and the Mean\n",
       "Squared Error for regression\n",
       "\\item[\\code{fitted}] logical indicating whether the fitted values should be computed\n",
       "and included in the model or not (default: \\code{TRUE})\n",
       "\\item[\\code{probability}] logical indicating whether the model should\n",
       "allow for probability predictions.\n",
       "\\item[\\code{...}] additional parameters for the low level fitting function\n",
       "\\code{svm.default}\n",
       "\\item[\\code{subset}] An index vector specifying the cases to be used in the\n",
       "training sample.  (NOTE: If given, this argument must be\n",
       "named.)\n",
       "\\item[\\code{na.action}] A function to specify the action to be taken if \\code{NA}s are\n",
       "found. The default action is \\code{na.omit}, which leads to rejection of cases\n",
       "with missing values on any required variable. An alternative\n",
       "is \\code{na.fail}, which causes an error if \\code{NA} cases\n",
       "are found. (NOTE: If given, this argument must be named.)\t\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "For multiclass-classification with k levels, k>2, \\code{libsvm} uses the\n",
       "`one-against-one'-approach, in which k(k-1)/2 binary classifiers are\n",
       "trained; the appropriate class is found by a voting scheme.\n",
       "\n",
       "\\code{libsvm} internally uses a sparse data representation, which is \n",
       "also high-level supported by the package \\pkg{SparseM}.\n",
       "\n",
       "If the predictor variables include factors, the formula interface must be used to get a\n",
       "correct model matrix.\n",
       "\n",
       "\\code{plot.svm} allows a simple graphical\n",
       "visualization of classification models.\n",
       "\n",
       "The probability model for classification fits a logistic distribution\n",
       "using maximum likelihood to the decision values of all binary\n",
       "classifiers, and computes the a-posteriori class probabilities for the\n",
       "multi-class problem using quadratic optimization. The probabilistic\n",
       "regression model assumes (zero-mean) laplace-distributed errors for the\n",
       "predictions, and estimates the scale parameter using maximum likelihood.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "An object of class \\code{\"svm\"} containing the fitted model, including:\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{SV}] The resulting support vectors (possibly scaled).\n",
       "\\item[\\code{index}] The index of the resulting support vectors in the data\n",
       "matrix. Note that this index refers to the preprocessed data (after\n",
       "the possible effect of \\code{na.omit} and \\code{subset})\n",
       "\\item[\\code{coefs}] The corresponding coefficients times the training labels.\n",
       "\\item[\\code{rho}] The negative intercept.\n",
       "\\item[\\code{sigma}] In case of a probabilistic regression model, the scale\n",
       "parameter of the hypothesized (zero-mean) laplace distribution estimated by\n",
       "maximum likelihood.\n",
       "\\item[\\code{probA, probB}] numeric vectors of length k(k-1)/2, k number of\n",
       "classes, containing the parameters of the logistic distributions fitted to\n",
       "the decision values of the binary classifiers (1 / (1 + exp(a x + b))).\n",
       "\\end{ldescription}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "Data are scaled internally, usually yielding better results.\n",
       "\n",
       "Parameters of SVM-models usually \\emph{must} be tuned to yield sensible results!\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin)\\\\{}\n",
       "\\email{David.Meyer@R-project.org}\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \n",
       "Chang, Chih-Chung and Lin, Chih-Jen:\\\\{}\n",
       "\\emph{LIBSVM: a library for Support Vector Machines}\\\\{}\n",
       "\\url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}\n",
       "\n",
       "\\item \n",
       "Exact formulations of models, algorithms, etc. can be found in the\n",
       "document:\\\\{}\n",
       "Chang, Chih-Chung and Lin, Chih-Jen:\\\\{}\n",
       "\\emph{LIBSVM: a library for Support Vector Machines}\\\\{}\n",
       "\\url{http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz}\n",
       "\n",
       "\\item \n",
       "More implementation details and speed benchmarks can be found on:\n",
       "Rong-En Fan and Pai-Hsune Chen and Chih-Jen Lin:\\\\{}\n",
       "\\emph{Working Set Selection Using the Second Order Information for Training SVM}\\\\{}\n",
       "\\url{http://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf}\n",
       "\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{predict.svm}{predict.svm}}\n",
       "\\code{\\LinkA{plot.svm}{plot.svm}}\n",
       "\\code{\\LinkA{tune.svm}{tune.svm}}\n",
       "\\code{\\LinkA{matrix.csr}{matrix.csr}} (in package \\pkg{SparseM})\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "data(iris)\n",
       "attach(iris)\n",
       "\n",
       "## classification mode\n",
       "# default with factor response:\n",
       "model <- svm(Species ~ ., data = iris)\n",
       "\n",
       "# alternatively the traditional interface:\n",
       "x <- subset(iris, select = -Species)\n",
       "y <- Species\n",
       "model <- svm(x, y) \n",
       "\n",
       "print(model)\n",
       "summary(model)\n",
       "\n",
       "# test with train data\n",
       "pred <- predict(model, x)\n",
       "# (same as:)\n",
       "pred <- fitted(model)\n",
       "\n",
       "# Check accuracy:\n",
       "table(pred, y)\n",
       "\n",
       "# compute decision values and probabilities:\n",
       "pred <- predict(model, x, decision.values = TRUE)\n",
       "attr(pred, \"decision.values\")[1:4,]\n",
       "\n",
       "# visualize (classes by color, SV by crosses):\n",
       "plot(cmdscale(dist(iris[,-5])),\n",
       "     col = as.integer(iris[,5]),\n",
       "     pch = c(\"o\",\"+\")[1:150 %in% model$index + 1])\n",
       "\n",
       "## try regression mode on two dimensions\n",
       "\n",
       "# create data\n",
       "x <- seq(0.1, 5, by = 0.05)\n",
       "y <- log(x) + rnorm(x, sd = 0.2)\n",
       "\n",
       "# estimate model and predict input values\n",
       "m   <- svm(x, y)\n",
       "new <- predict(m, x)\n",
       "\n",
       "# visualize\n",
       "plot(x, y)\n",
       "points(x, log(x), col = 2)\n",
       "points(x, new, col = 4)\n",
       "\n",
       "## density-estimation\n",
       "\n",
       "# create 2-dim. normal with rho=0:\n",
       "X <- data.frame(a = rnorm(1000), b = rnorm(1000))\n",
       "attach(X)\n",
       "\n",
       "# traditional way:\n",
       "m <- svm(X, gamma = 0.1)\n",
       "\n",
       "# formula interface:\n",
       "m <- svm(~., data = X, gamma = 0.1)\n",
       "# or:\n",
       "m <- svm(~ a + b, gamma = 0.1)\n",
       "\n",
       "# test:\n",
       "newdata <- data.frame(a = c(0, 4), b = c(0, 4))\n",
       "predict (m, newdata)\n",
       "\n",
       "# visualize:\n",
       "plot(X, col = 1:1000 %in% m$index + 1, xlim = c(-5,5), ylim=c(-5,5))\n",
       "points(newdata, pch = \"+\", col = 2, cex = 5)\n",
       "\n",
       "# weights: (example not particularly sensible)\n",
       "i2 <- iris\n",
       "levels(i2$Species)[3] <- \"versicolor\"\n",
       "summary(i2$Species)\n",
       "wts <- 100 / table(i2$Species)\n",
       "wts\n",
       "m <- svm(Species ~ ., data = i2, class.weights = wts)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "svm                   package:e1071                    R Documentation\n",
       "\n",
       "_\bS_\bu_\bp_\bp_\bo_\br_\bt _\bV_\be_\bc_\bt_\bo_\br _\bM_\ba_\bc_\bh_\bi_\bn_\be_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘svm’ is used to train a support vector machine. It can be used to\n",
       "     carry out general regression and classification (of nu and\n",
       "     epsilon-type), as well as density-estimation. A formula interface\n",
       "     is provided.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     ## S3 method for class 'formula'\n",
       "     svm(formula, data = NULL, ..., subset, na.action =\n",
       "     na.omit, scale = TRUE)\n",
       "     ## Default S3 method:\n",
       "     svm(x, y = NULL, scale = TRUE, type = NULL, kernel =\n",
       "     \"radial\", degree = 3, gamma = if (is.vector(x)) 1 else 1 / ncol(x),\n",
       "     coef0 = 0, cost = 1, nu = 0.5,\n",
       "     class.weights = NULL, cachesize = 40, tolerance = 0.001, epsilon = 0.1,\n",
       "     shrinking = TRUE, cross = 0, probability = FALSE, fitted = TRUE,\n",
       "     ..., subset, na.action = na.omit)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       " formula: a symbolic description of the model to be fit.\n",
       "\n",
       "    data: an optional data frame containing the variables in the model.\n",
       "          By default the variables are taken from the environment which\n",
       "          ‘svm’ is called from.\n",
       "\n",
       "       x: a data matrix, a vector, or a sparse matrix (object of class\n",
       "          ‘Matrix’ provided by the ‘Matrix’ package, or of class\n",
       "          ‘matrix.csr’ provided by the ‘SparseM’ package, or of class\n",
       "          ‘simple_triplet_matrix’ provided by the ‘slam’ package).\n",
       "\n",
       "       y: a response vector with one label for each row/component of\n",
       "          ‘x’. Can be either a factor (for classification tasks) or a\n",
       "          numeric vector (for regression).\n",
       "\n",
       "   scale: A logical vector indicating the variables to be scaled. If\n",
       "          ‘scale’ is of length 1, the value is recycled as many times\n",
       "          as needed.  Per default, data are scaled internally (both ‘x’\n",
       "          and ‘y’ variables) to zero mean and unit variance. The center\n",
       "          and scale values are returned and used for later predictions.\n",
       "\n",
       "    type: ‘svm’ can be used as a classification machine, as a\n",
       "          regression machine, or for novelty detection.  Depending of\n",
       "          whether ‘y’ is a factor or not, the default setting for\n",
       "          ‘type’ is ‘C-classification’ or ‘eps-regression’,\n",
       "          respectively, but may be overwritten by setting an explicit\n",
       "          value.\n",
       "          Valid options are:\n",
       "\n",
       "            • ‘C-classification’\n",
       "\n",
       "            • ‘nu-classification’\n",
       "\n",
       "            • ‘one-classification’ (for novelty detection)\n",
       "\n",
       "            • ‘eps-regression’\n",
       "\n",
       "            • ‘nu-regression’\n",
       "\n",
       "  kernel: the kernel used in training and predicting. You might\n",
       "          consider changing some of the following parameters, depending\n",
       "          on the kernel type.\n",
       "\n",
       "          linear: u'*v\n",
       "\n",
       "          polynomial: (gamma*u'*v + coef0)^degree\n",
       "\n",
       "          radial basis: exp(-gamma*|u-v|^2)\n",
       "\n",
       "          sigmoid: tanh(gamma*u'*v + coef0)\n",
       "\n",
       "  degree: parameter needed for kernel of type ‘polynomial’ (default: 3)\n",
       "\n",
       "   gamma: parameter needed for all kernels except ‘linear’ (default:\n",
       "          1/(data dimension))\n",
       "\n",
       "   coef0: parameter needed for kernels of type ‘polynomial’ and\n",
       "          ‘sigmoid’ (default: 0)\n",
       "\n",
       "    cost: cost of constraints violation (default: 1)-it is the\n",
       "          ‘C’-constant of the regularization term in the Lagrange\n",
       "          formulation.\n",
       "\n",
       "      nu: parameter needed for ‘nu-classification’, ‘nu-regression’,\n",
       "          and ‘one-classification’\n",
       "\n",
       "class.weights: a named vector of weights for the different classes,\n",
       "          used for asymmetric class sizes. Not all factor levels have\n",
       "          to be supplied (default weight: 1). All components have to be\n",
       "          named.\n",
       "\n",
       "cachesize: cache memory in MB (default 40)\n",
       "\n",
       "tolerance: tolerance of termination criterion (default: 0.001)\n",
       "\n",
       " epsilon: epsilon in the insensitive-loss function (default: 0.1)\n",
       "\n",
       "shrinking: option whether to use the shrinking-heuristics (default:\n",
       "          ‘TRUE’)\n",
       "\n",
       "   cross: if a integer value k>0 is specified, a k-fold cross\n",
       "          validation on the training data is performed to assess the\n",
       "          quality of the model: the accuracy rate for classification\n",
       "          and the Mean Squared Error for regression\n",
       "\n",
       "  fitted: logical indicating whether the fitted values should be\n",
       "          computed and included in the model or not (default: ‘TRUE’)\n",
       "\n",
       "probability: logical indicating whether the model should allow for\n",
       "          probability predictions.\n",
       "\n",
       "     ...: additional parameters for the low level fitting function\n",
       "          ‘svm.default’\n",
       "\n",
       "  subset: An index vector specifying the cases to be used in the\n",
       "          training sample.  (NOTE: If given, this argument must be\n",
       "          named.)\n",
       "\n",
       "na.action: A function to specify the action to be taken if ‘NA’s are\n",
       "          found. The default action is ‘na.omit’, which leads to\n",
       "          rejection of cases with missing values on any required\n",
       "          variable. An alternative is ‘na.fail’, which causes an error\n",
       "          if ‘NA’ cases are found. (NOTE: If given, this argument must\n",
       "          be named.)\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     For multiclass-classification with k levels, k>2, ‘libsvm’ uses\n",
       "     the ‘one-against-one’-approach, in which k(k-1)/2 binary\n",
       "     classifiers are trained; the appropriate class is found by a\n",
       "     voting scheme.\n",
       "\n",
       "     ‘libsvm’ internally uses a sparse data representation, which is\n",
       "     also high-level supported by the package ‘SparseM’.\n",
       "\n",
       "     If the predictor variables include factors, the formula interface\n",
       "     must be used to get a correct model matrix.\n",
       "\n",
       "     ‘plot.svm’ allows a simple graphical visualization of\n",
       "     classification models.\n",
       "\n",
       "     The probability model for classification fits a logistic\n",
       "     distribution using maximum likelihood to the decision values of\n",
       "     all binary classifiers, and computes the a-posteriori class\n",
       "     probabilities for the multi-class problem using quadratic\n",
       "     optimization. The probabilistic regression model assumes\n",
       "     (zero-mean) laplace-distributed errors for the predictions, and\n",
       "     estimates the scale parameter using maximum likelihood.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     An object of class ‘\"svm\"’ containing the fitted model, including:\n",
       "\n",
       "      SV: The resulting support vectors (possibly scaled).\n",
       "\n",
       "   index: The index of the resulting support vectors in the data\n",
       "          matrix. Note that this index refers to the preprocessed data\n",
       "          (after the possible effect of ‘na.omit’ and ‘subset’)\n",
       "\n",
       "   coefs: The corresponding coefficients times the training labels.\n",
       "\n",
       "     rho: The negative intercept.\n",
       "\n",
       "   sigma: In case of a probabilistic regression model, the scale\n",
       "          parameter of the hypothesized (zero-mean) laplace\n",
       "          distribution estimated by maximum likelihood.\n",
       "\n",
       "probA, probB: numeric vectors of length k(k-1)/2, k number of classes,\n",
       "          containing the parameters of the logistic distributions\n",
       "          fitted to the decision values of the binary classifiers (1 /\n",
       "          (1 + exp(a x + b))).\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     Data are scaled internally, usually yielding better results.\n",
       "\n",
       "     Parameters of SVM-models usually _must_ be tuned to yield sensible\n",
       "     results!\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     David Meyer (based on C/C++-code by Chih-Chung Chang and Chih-Jen\n",
       "     Lin)\n",
       "     <email: David.Meyer@R-project.org>\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "        • Chang, Chih-Chung and Lin, Chih-Jen:\n",
       "          _LIBSVM: a library for Support Vector Machines_\n",
       "          <URL: http://www.csie.ntu.edu.tw/~cjlin/libsvm>\n",
       "\n",
       "        • Exact formulations of models, algorithms, etc. can be found\n",
       "          in the document:\n",
       "          Chang, Chih-Chung and Lin, Chih-Jen:\n",
       "          _LIBSVM: a library for Support Vector Machines_\n",
       "          <URL: http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz>\n",
       "\n",
       "        • More implementation details and speed benchmarks can be found\n",
       "          on: Rong-En Fan and Pai-Hsune Chen and Chih-Jen Lin:\n",
       "          _Working Set Selection Using the Second Order Information for\n",
       "          Training SVM_\n",
       "          <URL:\n",
       "          http://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf>\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘predict.svm’ ‘plot.svm’ ‘tune.svm’ ‘matrix.csr’ (in package\n",
       "     ‘SparseM’)\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     data(iris)\n",
       "     attach(iris)\n",
       "     \n",
       "     ## classification mode\n",
       "     # default with factor response:\n",
       "     model <- svm(Species ~ ., data = iris)\n",
       "     \n",
       "     # alternatively the traditional interface:\n",
       "     x <- subset(iris, select = -Species)\n",
       "     y <- Species\n",
       "     model <- svm(x, y) \n",
       "     \n",
       "     print(model)\n",
       "     summary(model)\n",
       "     \n",
       "     # test with train data\n",
       "     pred <- predict(model, x)\n",
       "     # (same as:)\n",
       "     pred <- fitted(model)\n",
       "     \n",
       "     # Check accuracy:\n",
       "     table(pred, y)\n",
       "     \n",
       "     # compute decision values and probabilities:\n",
       "     pred <- predict(model, x, decision.values = TRUE)\n",
       "     attr(pred, \"decision.values\")[1:4,]\n",
       "     \n",
       "     # visualize (classes by color, SV by crosses):\n",
       "     plot(cmdscale(dist(iris[,-5])),\n",
       "          col = as.integer(iris[,5]),\n",
       "          pch = c(\"o\",\"+\")[1:150 %in% model$index + 1])\n",
       "     \n",
       "     ## try regression mode on two dimensions\n",
       "     \n",
       "     # create data\n",
       "     x <- seq(0.1, 5, by = 0.05)\n",
       "     y <- log(x) + rnorm(x, sd = 0.2)\n",
       "     \n",
       "     # estimate model and predict input values\n",
       "     m   <- svm(x, y)\n",
       "     new <- predict(m, x)\n",
       "     \n",
       "     # visualize\n",
       "     plot(x, y)\n",
       "     points(x, log(x), col = 2)\n",
       "     points(x, new, col = 4)\n",
       "     \n",
       "     ## density-estimation\n",
       "     \n",
       "     # create 2-dim. normal with rho=0:\n",
       "     X <- data.frame(a = rnorm(1000), b = rnorm(1000))\n",
       "     attach(X)\n",
       "     \n",
       "     # traditional way:\n",
       "     m <- svm(X, gamma = 0.1)\n",
       "     \n",
       "     # formula interface:\n",
       "     m <- svm(~., data = X, gamma = 0.1)\n",
       "     # or:\n",
       "     m <- svm(~ a + b, gamma = 0.1)\n",
       "     \n",
       "     # test:\n",
       "     newdata <- data.frame(a = c(0, 4), b = c(0, 4))\n",
       "     predict (m, newdata)\n",
       "     \n",
       "     # visualize:\n",
       "     plot(X, col = 1:1000 %in% m$index + 1, xlim = c(-5,5), ylim=c(-5,5))\n",
       "     points(newdata, pch = \"+\", col = 2, cex = 5)\n",
       "     \n",
       "     # weights: (example not particularly sensible)\n",
       "     i2 <- iris\n",
       "     levels(i2$Species)[3] <- \"versicolor\"\n",
       "     summary(i2$Species)\n",
       "     wts <- 100 / table(i2$Species)\n",
       "     wts\n",
       "     m <- svm(Species ~ ., data = i2, class.weights = wts)\n",
       "     "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
